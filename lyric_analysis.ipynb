{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics Using Genius API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import lyricsgenius as genius #used to interface with Genius API\n",
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token provided by Genius API\n",
    "%store -r client_access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate Genius\n",
    "genius = genius.Genius(client_access_token)\n",
    "genius.verbose = False #turn off status messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics(track,artist):\n",
    "    '''\n",
    "    function returns song's lyrics\n",
    "    parameters:\n",
    "        track-->str\n",
    "        artist-->str\n",
    "    '''\n",
    "    track = re.sub(' - .+','',track) #remove text after '-'\n",
    "    track = re.sub(' \\(.*\\)','',track) #remove text within parentheses\n",
    "    track = re.sub(' \\[.*\\]','',track) #remove text within brackets\n",
    "    \n",
    "    try:\n",
    "        return genius.search_song(track,artist).lyrics\n",
    "    except:\n",
    "        print(track + ' by ' + artist + ' is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_songs(track_list,artist_list):\n",
    "    '''\n",
    "    function obtains lyrics and returns dataframe with columns for track, artist, lyrics\n",
    "    parameters:\n",
    "        track_list-->list of str \n",
    "        artist_list-->list of str\n",
    "    '''\n",
    "    lyrics_list = [get_lyrics(track_list[x],artist_list[x]) for x in range(len(track_list))] #get lyrics for each song\n",
    "    \n",
    "    return pd.DataFrame(data={'track':track_list,'artist':artist_list,'lyrics':lyrics_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(df,col,new_col):\n",
    "    '''\n",
    "    function returns dataframe with new column of cleaned text (song lyrics)\n",
    "    parameters:\n",
    "        df-->pandas dataframe\n",
    "        col-->column to clean (str)\n",
    "        new_col-->name of column with cleaned text (str)\n",
    "    '''\n",
    "    df[new_col] = df[col].str.lower() #make all text lowercase\n",
    "    df[new_col] = df[new_col].str.replace(r'\\n',' ') #replace '\\n' character with space\n",
    "    df[new_col] = df[new_col].str.replace(r'\\[[^\\[\\]]*]','') #remove brackets and inside text\n",
    "    df[new_col] = df[new_col].str.replace(r\"\\'\\w*\",'').str.replace(r'[^\\w\\d\\s]+','') #remove extra characters\n",
    "    df[new_col] = df[new_col].str.strip() #remove extra whitespace\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lyrics(df,col):\n",
    "    '''\n",
    "    function returns dataframe with column as list of words\n",
    "        tokenizes, removes stopwords from, and lemmatizes lyrics\n",
    "    parameters:\n",
    "        df-->pandas dataframe\n",
    "        col-->column to normalize\n",
    "    '''\n",
    "\n",
    "    df[col] = df[col].str.split() #tokenize lyrics\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df[col] = df[col].apply(lambda row: [w for w in row if w not in stop_words]) #remove stopwords\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def lemmatize_text(text):\n",
    "        '''\n",
    "        function returns lemmatized text\n",
    "        parameters:\n",
    "            text-->str\n",
    "        '''\n",
    "        return [lemmatizer.lemmatize(w) for w in text]\n",
    "    \n",
    "    df[col] = df[col].apply(lemmatize_text) #lemmatize words\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Songs to Analyze\n",
    "\n",
    "Read in the resulting dataframes from the spotify_analysis notebook, which were created as follows:\n",
    "\n",
    " - Started with the top five tracks for each of country, R&B/hip-hop, and rock/alternative as of the week of May 15, 2021, based on Billboard Top 100 charts (referred to as the \"seed tracks\")\n",
    " - Used Spotify's recommender algorithm to find the most similar songs to the seed tracks (returns a maximum of 100 songs per search)\n",
    " - Ranked the most similar songs by audio features using Euclidean distance\n",
    " - Fed the top ranking songs through Spotify's recommender algorithm until there were at least 1,000 songs per genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country\n",
    "df_cty = pd.read_csv('data/df_cty.csv')\n",
    "df_cty.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R&B/hip-hop\n",
    "df_rb = pd.read_csv('data/df_rb.csv')\n",
    "df_rb.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rock/alternative\n",
    "df_rock = pd.read_csv('data/df_rock.csv')\n",
    "df_rock.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Lyrics from Genius API\n",
    "\n",
    "Pull lyrics from the Genius API with the lyricsgenius wrapper and put into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Beer by HIXTAPE is not available\n",
      "Ballin' by Rvshvd is not available\n",
      "Gabrielle by Brett Eldredge is not available\n",
      "Forever Begins Tonight by The McClymonts is not available\n",
      "Tupelo Honey by JJ Grey & Mofro is not available\n",
      "#REDNEK by Gord Bamford is not available\n"
     ]
    }
   ],
   "source": [
    "#country\n",
    "df_cty_lyrics = get_df_songs(df_cty['track'],df_cty['artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bang Bang by Jessie J is not available\n",
      "Before He Cheats by Carrie Underwood is not available\n",
      "See What I've Become by Zack Hemsey is not available\n",
      "Stinger by RL Grime is not available\n",
      "Money On The Table by Belly is not available\n"
     ]
    }
   ],
   "source": [
    "#R&B/hip-hop\n",
    "df_rb_lyrics = get_df_songs(df_rb['track'],df_rb['artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greatest Hits Megamix by The Saturdays is not available\n",
      "Smells Blood by Kensuke Ushio is not available\n",
      "Ghost by Machine Girl is not available\n",
      "Unforgettable by French Montana is not available\n"
     ]
    }
   ],
   "source": [
    "#rock\n",
    "df_rock_lyrics = get_df_songs(df_rock['track'],df_rock['artist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Preprocess Lyrics\n",
    "\n",
    "Prepare lyrics for analysis by cleaning and normalizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows without lyrics\n",
    "df_cty_w_lyrics = df_cty_lyrics.dropna(subset=['lyrics']) #country\n",
    "df_rb_w_lyrics = df_rb_lyrics.dropna(subset=['lyrics']) #R&B/hip-hop\n",
    "df_rock_w_lyrics = df_rock_lyrics.dropna(subset=['lyrics']) #rock/alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean lyrics\n",
    "#df_cty_cleaned = clean_lyrics(df_cty_w_lyrics,'lyrics','words')\n",
    "df_rb_cleaned = clean_lyrics(df_rb_w_lyrics,'lyrics','words')\n",
    "#df_rock_cleaned = clean_lyrics(df_rock_w_lyrics,'lyrics','words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize \n",
    "draft2 = normalize_lyrics(df_rb_cleaned,'words')\n",
    "#df_cty_w_lyrics = normalize_lyrics(df_cty_w_lyrics,'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Bruno Mars</td>\n",
       "      <td>1. Bruno Mars, Anderson .Paak &amp; Silk Sonic- Le...</td>\n",
       "      <td>[1, bruno, mar, anderson, paak, silk, sonic, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peaches (feat. Daniel Caesar &amp; Giveon)</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>[Chorus: Justin Bieber]\\nI got my peaches out ...</td>\n",
       "      <td>[got, peach, georgia, oh, yeah, shit, get, wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RAPSTAR</td>\n",
       "      <td>Polo G</td>\n",
       "      <td>[Intro]\\n(Shout out my nigga Synco)\\n\\n[Chorus...</td>\n",
       "      <td>[shout, nigga, synco, uh, tuned, copped, bmw, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Astronaut In The Ocean</td>\n",
       "      <td>Masked Wolf</td>\n",
       "      <td>[Intro]\\nAstro-naut\\n\\n[Chorus]\\nWhat you know...</td>\n",
       "      <td>[astronaut, know, rollin, deep, brain, go, num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Up</td>\n",
       "      <td>Cardi B</td>\n",
       "      <td>[Intro]\\nUp, up, up (Ayy), up (Uh), up, look (...</td>\n",
       "      <td>[ayy, uh, look, fire, upon, time, man, heard, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>Play With Fire</td>\n",
       "      <td>Nico Santos</td>\n",
       "      <td>[Verse 1]\\nIt's only been about a couple of da...</td>\n",
       "      <td>[couple, day, must, gone, put, spell, get, vei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>WOW (feat. Sabrina Carpenter) - Remix</td>\n",
       "      <td>Zara Larsson</td>\n",
       "      <td>[Chorus]\\nBaby, I'm not even in a gown\\nI'm ju...</td>\n",
       "      <td>[baby, even, gown, tshirt, couch, way, want, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>Unfamiliar</td>\n",
       "      <td>Seeb</td>\n",
       "      <td>[Verse 1: HRVY]\\nStood outside, I need to calm...</td>\n",
       "      <td>[stood, outside, need, calm, head, heart, cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>501</td>\n",
       "      <td>Various Artists</td>\n",
       "      <td>Eric S. Reed; Soldier's Hymn Music Inc.; Willi...</td>\n",
       "      <td>[eric, reed, soldier, hymn, music, inc, willie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>Nice to Meet Ya (feat. Nicki Minaj)</td>\n",
       "      <td>Meghan Trainor</td>\n",
       "      <td>[Intro: Meghan Trainor &amp; Nicki Minaj]\\nNice to...</td>\n",
       "      <td>[nice, meet, ya, mmm, ooh, nice, meet, ya, ooh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       track           artist  \\\n",
       "0                        Leave The Door Open       Bruno Mars   \n",
       "1     Peaches (feat. Daniel Caesar & Giveon)    Justin Bieber   \n",
       "2                                    RAPSTAR           Polo G   \n",
       "3                     Astronaut In The Ocean      Masked Wolf   \n",
       "4                                         Up          Cardi B   \n",
       "...                                      ...              ...   \n",
       "1009                          Play With Fire      Nico Santos   \n",
       "1010   WOW (feat. Sabrina Carpenter) - Remix     Zara Larsson   \n",
       "1011                              Unfamiliar             Seeb   \n",
       "1012                                     501  Various Artists   \n",
       "1013     Nice to Meet Ya (feat. Nicki Minaj)   Meghan Trainor   \n",
       "\n",
       "                                                 lyrics  \\\n",
       "0     1. Bruno Mars, Anderson .Paak & Silk Sonic- Le...   \n",
       "1     [Chorus: Justin Bieber]\\nI got my peaches out ...   \n",
       "2     [Intro]\\n(Shout out my nigga Synco)\\n\\n[Chorus...   \n",
       "3     [Intro]\\nAstro-naut\\n\\n[Chorus]\\nWhat you know...   \n",
       "4     [Intro]\\nUp, up, up (Ayy), up (Uh), up, look (...   \n",
       "...                                                 ...   \n",
       "1009  [Verse 1]\\nIt's only been about a couple of da...   \n",
       "1010  [Chorus]\\nBaby, I'm not even in a gown\\nI'm ju...   \n",
       "1011  [Verse 1: HRVY]\\nStood outside, I need to calm...   \n",
       "1012  Eric S. Reed; Soldier's Hymn Music Inc.; Willi...   \n",
       "1013  [Intro: Meghan Trainor & Nicki Minaj]\\nNice to...   \n",
       "\n",
       "                                                  words  \n",
       "0     [1, bruno, mar, anderson, paak, silk, sonic, l...  \n",
       "1     [got, peach, georgia, oh, yeah, shit, get, wee...  \n",
       "2     [shout, nigga, synco, uh, tuned, copped, bmw, ...  \n",
       "3     [astronaut, know, rollin, deep, brain, go, num...  \n",
       "4     [ayy, uh, look, fire, upon, time, man, heard, ...  \n",
       "...                                                 ...  \n",
       "1009  [couple, day, must, gone, put, spell, get, vei...  \n",
       "1010  [baby, even, gown, tshirt, couch, way, want, m...  \n",
       "1011  [stood, outside, need, calm, head, heart, cont...  \n",
       "1012  [eric, reed, soldier, hymn, music, inc, willie...  \n",
       "1013  [nice, meet, ya, mmm, ooh, nice, meet, ya, ooh...  \n",
       "\n",
       "[1009 rows x 4 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-3769df6e9655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_rb_w_lyrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_rb_lyrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lyrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_rb_w_lyrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_lyrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rb_w_lyrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lyrics'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_rb_w_lyrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_lyrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rb_w_lyrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-194-fd1b3bbfaebd>\u001b[0m in \u001b[0;36mnormalize_lyrics\u001b[0;34m(df, col)\u001b[0m\n\u001b[1;32m      8\u001b[0m     '''\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#tokenize lyrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#str.split()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-194-fd1b3bbfaebd>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      8\u001b[0m     '''\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#tokenize lyrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#str.split()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "#R&B/hip-hop\n",
    "#df_rb2 = df_rb_lyrics.dropna(subset=['lyrics'])\n",
    "df_rb_w_lyrics = df_rb_lyrics.dropna(subset=['lyrics'])\n",
    "df_rb_w_lyrics = clean_lyrics(df_rb_w_lyrics,'lyrics','words')\n",
    "df_rb_w_lyrics = normalize_lyrics(df_rb_w_lyrics,'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'words'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-2a0785b63526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_rb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_lyrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rb2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lyrics'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_rb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_lyrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rb2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-185-d92dff99b7d4>\u001b[0m in \u001b[0;36mnormalize_lyrics\u001b[0;34m(df, col)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcol\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0mto\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     '''\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#tokenize lyrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'words'"
     ]
    }
   ],
   "source": [
    "#df_rb2 = clean_lyrics(df_rb2,'lyrics','words')\n",
    "#df_rb2 = normalize_lyrics(df_rb2,'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Bruno Mars</td>\n",
       "      <td>1. Bruno Mars, Anderson .Paak &amp; Silk Sonic- Le...</td>\n",
       "      <td>[n, n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peaches (feat. Daniel Caesar &amp; Giveon)</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>[Chorus: Justin Bieber]\\nI got my peaches out ...</td>\n",
       "      <td>[n, n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RAPSTAR</td>\n",
       "      <td>Polo G</td>\n",
       "      <td>[Intro]\\n(Shout out my nigga Synco)\\n\\n[Chorus...</td>\n",
       "      <td>[n, n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Astronaut In The Ocean</td>\n",
       "      <td>Masked Wolf</td>\n",
       "      <td>[Intro]\\nAstro-naut\\n\\n[Chorus]\\nWhat you know...</td>\n",
       "      <td>[n, n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Up</td>\n",
       "      <td>Cardi B</td>\n",
       "      <td>[Intro]\\nUp, up, up (Ayy), up (Uh), up, look (...</td>\n",
       "      <td>[n, n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>Play With Fire</td>\n",
       "      <td>Nico Santos</td>\n",
       "      <td>[Verse 1]\\nIt's only been about a couple of da...</td>\n",
       "      <td>[n, n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>WOW (feat. Sabrina Carpenter) - Remix</td>\n",
       "      <td>Zara Larsson</td>\n",
       "      <td>[Chorus]\\nBaby, I'm not even in a gown\\nI'm ju...</td>\n",
       "      <td>[n, n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>Unfamiliar</td>\n",
       "      <td>Seeb</td>\n",
       "      <td>[Verse 1: HRVY]\\nStood outside, I need to calm...</td>\n",
       "      <td>[n, n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>501</td>\n",
       "      <td>Various Artists</td>\n",
       "      <td>Eric S. Reed; Soldier's Hymn Music Inc.; Willi...</td>\n",
       "      <td>[n, n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>Nice to Meet Ya (feat. Nicki Minaj)</td>\n",
       "      <td>Meghan Trainor</td>\n",
       "      <td>[Intro: Meghan Trainor &amp; Nicki Minaj]\\nNice to...</td>\n",
       "      <td>[n, n]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       track           artist  \\\n",
       "0                        Leave The Door Open       Bruno Mars   \n",
       "1     Peaches (feat. Daniel Caesar & Giveon)    Justin Bieber   \n",
       "2                                    RAPSTAR           Polo G   \n",
       "3                     Astronaut In The Ocean      Masked Wolf   \n",
       "4                                         Up          Cardi B   \n",
       "...                                      ...              ...   \n",
       "1009                          Play With Fire      Nico Santos   \n",
       "1010   WOW (feat. Sabrina Carpenter) - Remix     Zara Larsson   \n",
       "1011                              Unfamiliar             Seeb   \n",
       "1012                                     501  Various Artists   \n",
       "1013     Nice to Meet Ya (feat. Nicki Minaj)   Meghan Trainor   \n",
       "\n",
       "                                                 lyrics    word  \n",
       "0     1. Bruno Mars, Anderson .Paak & Silk Sonic- Le...  [n, n]  \n",
       "1     [Chorus: Justin Bieber]\\nI got my peaches out ...  [n, n]  \n",
       "2     [Intro]\\n(Shout out my nigga Synco)\\n\\n[Chorus...  [n, n]  \n",
       "3     [Intro]\\nAstro-naut\\n\\n[Chorus]\\nWhat you know...  [n, n]  \n",
       "4     [Intro]\\nUp, up, up (Ayy), up (Uh), up, look (...  [n, n]  \n",
       "...                                                 ...     ...  \n",
       "1009  [Verse 1]\\nIt's only been about a couple of da...  [n, n]  \n",
       "1010  [Chorus]\\nBaby, I'm not even in a gown\\nI'm ju...  [n, n]  \n",
       "1011  [Verse 1: HRVY]\\nStood outside, I need to calm...  [n, n]  \n",
       "1012  Eric S. Reed; Soldier's Hymn Music Inc.; Willi...  [n, n]  \n",
       "1013  [Intro: Meghan Trainor & Nicki Minaj]\\nNice to...  [n, n]  \n",
       "\n",
       "[1004 rows x 4 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_rb2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-e48a0899c508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_rock_w_lyrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_rock_lyrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lyrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_rock_w_lyrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_lyrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rock_w_lyrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lyrics'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_rock_w_lyrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_lyrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rock_w_lyrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-117-a802c7c512a7>\u001b[0m in \u001b[0;36mnormalize_lyrics\u001b[0;34m(df, col)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#remove stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlemmatizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-a802c7c512a7>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#remove stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlemmatizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "#rock/alternative\n",
    "#df_rock_w_lyrics = df_rock_lyrics.dropna(subset=['lyrics'])\n",
    "#df_rock_w_lyrics = clean_lyrics(df_rock_w_lyrics,'lyrics','words')\n",
    "#df_rock_w_lyrics = normalize_lyrics(df_rock_w_lyrics,'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WITHOUT YOU</td>\n",
       "      <td>The Kid LAROI</td>\n",
       "      <td>[Chorus]\\nYou cut out a piece of me and now I ...</td>\n",
       "      <td>[you, cut, out, a, piece, of, me, and, now, i,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your Power</td>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>[Chorus]\\nTry not to abuse your power\\nI know ...</td>\n",
       "      <td>[try, not, to, abuse, your, power, i, know, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my ex's best friend (with blackbear)</td>\n",
       "      <td>Machine Gun Kelly</td>\n",
       "      <td>[Intro: Machine Gun Kelly &amp; blackbear]\\nAyy\\nY...</td>\n",
       "      <td>[ayy, you, know, my, ex, so, that, makes, it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mood (feat. iann dior)</td>\n",
       "      <td>24kGoldn</td>\n",
       "      <td>[Intro: 24kGoldn]\\nOh-oh-oh\\nYeah, yeah, yeah,...</td>\n",
       "      <td>[ohohoh, yeah, yeah, yeah, yeah, yeah, why, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Therefore I Am</td>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>[Chorus]\\nI'm not your friend\\nOr anything, da...</td>\n",
       "      <td>[i, not, your, friend, or, anything, damn, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>Umbrella</td>\n",
       "      <td>Rihanna</td>\n",
       "      <td>[Intro: JAY-Z]\\nUh-huh, uh-huh (Yeah, Rihanna)...</td>\n",
       "      <td>[uhhuh, uhhuh, yeah, rihanna, uhhuh, uhhuh, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>Girls in the Hood</td>\n",
       "      <td>Megan Thee Stallion</td>\n",
       "      <td>[Verse 1]\\nFuck bein' good, I'm a bad bitch (A...</td>\n",
       "      <td>[fuck, bein, good, i, a, bad, bitch, ah, i, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>Partition</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>[Part 1: \"Yoncé\"]\\n\\n[Intro]\\nLet me hear you ...</td>\n",
       "      <td>[let, me, hear, you, say, hey, ms, carter, hey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>Single Ladies (Put a Ring on It)</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Sorted  by featured singer\\n\\nRobyn Adele Ande...</td>\n",
       "      <td>[sorted, by, featured, singer, robyn, adele, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>That's My Girl</td>\n",
       "      <td>Fifth Harmony</td>\n",
       "      <td>[Intro: Camila]\\nThat's my girl\\n\\n[Verse 1: A...</td>\n",
       "      <td>[that, my, girl, yeah, who, been, working, so,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1075 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     track               artist  \\\n",
       "0                              WITHOUT YOU        The Kid LAROI   \n",
       "1                               Your Power        Billie Eilish   \n",
       "2     my ex's best friend (with blackbear)    Machine Gun Kelly   \n",
       "3                   Mood (feat. iann dior)             24kGoldn   \n",
       "4                           Therefore I Am        Billie Eilish   \n",
       "...                                    ...                  ...   \n",
       "1070                              Umbrella              Rihanna   \n",
       "1071                     Girls in the Hood  Megan Thee Stallion   \n",
       "1072                             Partition              Beyoncé   \n",
       "1073      Single Ladies (Put a Ring on It)              Beyoncé   \n",
       "1074                        That's My Girl        Fifth Harmony   \n",
       "\n",
       "                                                 lyrics  \\\n",
       "0     [Chorus]\\nYou cut out a piece of me and now I ...   \n",
       "1     [Chorus]\\nTry not to abuse your power\\nI know ...   \n",
       "2     [Intro: Machine Gun Kelly & blackbear]\\nAyy\\nY...   \n",
       "3     [Intro: 24kGoldn]\\nOh-oh-oh\\nYeah, yeah, yeah,...   \n",
       "4     [Chorus]\\nI'm not your friend\\nOr anything, da...   \n",
       "...                                                 ...   \n",
       "1070  [Intro: JAY-Z]\\nUh-huh, uh-huh (Yeah, Rihanna)...   \n",
       "1071  [Verse 1]\\nFuck bein' good, I'm a bad bitch (A...   \n",
       "1072  [Part 1: \"Yoncé\"]\\n\\n[Intro]\\nLet me hear you ...   \n",
       "1073  Sorted  by featured singer\\n\\nRobyn Adele Ande...   \n",
       "1074  [Intro: Camila]\\nThat's my girl\\n\\n[Verse 1: A...   \n",
       "\n",
       "                                                  words  \n",
       "0     [you, cut, out, a, piece, of, me, and, now, i,...  \n",
       "1     [try, not, to, abuse, your, power, i, know, we...  \n",
       "2     [ayy, you, know, my, ex, so, that, makes, it, ...  \n",
       "3     [ohohoh, yeah, yeah, yeah, yeah, yeah, why, yo...  \n",
       "4     [i, not, your, friend, or, anything, damn, you...  \n",
       "...                                                 ...  \n",
       "1070  [uhhuh, uhhuh, yeah, rihanna, uhhuh, uhhuh, go...  \n",
       "1071  [fuck, bein, good, i, a, bad, bitch, ah, i, si...  \n",
       "1072  [let, me, hear, you, say, hey, ms, carter, hey...  \n",
       "1073  [sorted, by, featured, singer, robyn, adele, a...  \n",
       "1074  [that, my, girl, yeah, who, been, working, so,...  \n",
       "\n",
       "[1075 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_rock_w_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "track                                              Medicine\n",
       "artist                                         James Arthur\n",
       "lyrics    [Verse 1]\\nYou're my bulletproof vest when it'...\n",
       "words     [you, my, bulletproof, vest, when, it, getting...\n",
       "Name: 1000, dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rb_lyrics.iloc[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Dataframes\n",
    "\n",
    "Combine dataframes with audio features and lyrics for each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country\n",
    "#df_cty_w_lyrics = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R&B/hip-hop\n",
    "#df_rb_w_lyrics = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rock/alternative\n",
    "#df_rock_w_lyrics = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Dataframes to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country\n",
    "#df_cty_w_lyrics.to_csv('df_cty_w_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R&B/hip-hop\n",
    "#df_rb_w_lyrics.to_csv('df_rb_w_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rock/alternative\n",
    "#df_rock_w_lyrics.to_csv('df_rock_w_lyrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
