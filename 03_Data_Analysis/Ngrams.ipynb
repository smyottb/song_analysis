{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from py4tfidf.vectorizer import Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cty = pd.read_csv('../Data/df_for_cty_ngrams.csv').fillna('NA')\n",
    "df_rock = pd.read_csv('../Data/df_for_rock_ngrams.csv').fillna('NA')\n",
    "df_rb = pd.read_csv('../Data/df_for_rb_ngrams').fillna('NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(line):\n",
    "    #WORD_RE = re.compile(r\"[A-Za-z0-9_\\-]+\")\n",
    "    WORD_RE = re.compile(r'\\b\\S+\\b')\n",
    "    token = WORD_RE.findall(line)\n",
    "    tokens = [w.lower().replace('\\\\u',' ').replace(\"205f\",'').replace(\"2005\",'').replace(\"\\\\\",'') for w in token if w.lower()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_lines(df):  \n",
    "    all_list = []\n",
    "    for column in df:\n",
    "        for corpus in df[column]:\n",
    "            x = remove_stop(corpus.strip(']['))\n",
    "            all_list.append(x)\n",
    "    return all_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tfidf stands fro Term frequency * inverse document frequency\n",
    "- Helps standardize if a  word/phrase shows up alot in one document, causing the frequency to be inflated, making it seem more important than it is\n",
    "- Ngram range (3,5): I looked at ngrams of size 3,4,5\n",
    "- Sorted by tfidf value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_output(words):\n",
    "    final = []\n",
    "    for i in words:\n",
    "        song = []\n",
    "        for j in i:\n",
    "            temp = []\n",
    "            tokens = j.split(' ')\n",
    "            if len(tokens) > 1:\n",
    "                for item in tokens:\n",
    "                    temp.append(item)\n",
    "            else:\n",
    "                temp.append(j)\n",
    "            song.extend(temp)\n",
    "        final.append(song)\n",
    "    text = [\" \".join(i)for i in final]\n",
    "    \n",
    "    \n",
    "    vectorizer = TfidfVectorizer(ngram_range = (3,5), min_df =5)\n",
    "    vectorizer.fit(text)\n",
    "    \n",
    "    vector = vectorizer.transform([text[0]])\n",
    "    counts = vectorizer.vocabulary_\n",
    "    idfs = vectorizer.idf_\n",
    "    \n",
    "    output = pd.DataFrame(zip(list(counts.keys()) , idfs), columns = ['phrase','idf'])\n",
    "    \n",
    "    count_df = pd.DataFrame(zip(list(counts.keys()), list(counts.values())), columns = ['phrase', 'counts'])\n",
    "                        \n",
    "                    \n",
    "    data = pd.merge(output , count_df)\n",
    "    data['tfidf'] = data.idf * data.counts\n",
    "    data['length'] = [len(i.split(' ')) for i in data.phrase]\n",
    "    \n",
    "    #data_two = data[data.length == 2].sort_values('tfidf', ascending = False).head(5)\n",
    "    data_three = data[data.length == 3].sort_values('tfidf', ascending = False).head(5)\n",
    "    data_four = data[data.length == 4].sort_values('tfidf', ascending = False).head(5)\n",
    "    data_five = data[data.length == 5].sort_values('tfidf', ascending = False).head(5)\n",
    "    \n",
    "    data = pd.concat((data_three , data_four , data_five))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RB output for Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_analysis = ['Intro', 'Chorus' ,'Verse 1', 'Chorus', 'Verse 2' ,'Chorus']\n",
    "\n",
    "\n",
    "df_rb_last = pd.DataFrame(columns = ['phrase','idf','tfidf','length'])\n",
    "for i in features_for_analysis:\n",
    "    words = get_cleaned_lines(df_rb[[i]])\n",
    "    temp = final_output(words)\n",
    "    temp['Song_Part'] = i\n",
    "    df_rb_last = pd.concat((df_rb_last , temp))\n",
    "df_rb_last = df_rb_last.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rock output for Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_analysis =['Verse 1', 'Pre-Chorus' ,'Chorus', 'Verse 2' ,'Pre-Chorus' ,'Chorus' ,'Bridge' ,'Chorus']\n",
    "\n",
    "df_rock_last = pd.DataFrame(columns = ['phrase','idf','tfidf','length'])\n",
    "for i in features_for_analysis:\n",
    "    words = get_cleaned_lines(df_rock[[i]])\n",
    "    temp = final_output(words)\n",
    "    temp['Song_Part'] = i\n",
    "    df_rock_last = pd.concat((df_rock_last , temp))\n",
    "df_rock_last = df_rock_last.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country output for Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_analysis = ['Verse 1' ,'Chorus', 'Verse 2' ,'Chorus', 'Bridge' ,'Chorus']\n",
    "\n",
    "\n",
    "df_cty_last = pd.DataFrame(columns = ['phrase','idf','tfidf','length'])\n",
    "for i in features_for_analysis:\n",
    "    words = get_cleaned_lines(df_cty[[i]])\n",
    "    temp = final_output(words)\n",
    "    temp['Song_Part'] = i\n",
    "    df_cty_last = pd.concat((df_cty_last , temp))\n",
    "df_cty_last = df_cty_last.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rb_last.to_csv('../Data/ngrams_df_rb.csv', index = False)\n",
    "df_rock_last.to_csv('../Data/ngrams_df_rock.csv', index = False)\n",
    "df_cty_last.to_csv('../Data/ngrams_df_cty.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
