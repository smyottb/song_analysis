{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics Using Genius API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import lyricsgenius as genius #used to interface with Genius API\n",
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token provided by Genius API\n",
    "%store -r client_access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate Genius\n",
    "genius = genius.Genius(client_access_token)\n",
    "genius.verbose = False #turn off status messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics(track,artist):\n",
    "    '''\n",
    "    function returns song's lyrics\n",
    "    parameters:\n",
    "        track-->str\n",
    "        artist-->str\n",
    "    '''\n",
    "    track = re.sub(' - .+','',track) #remove text after '-'\n",
    "    track = re.sub(' \\(.*\\)','',track) #remove text within parentheses\n",
    "    track = re.sub(' \\[.*\\]','',track) #remove text within brackets\n",
    "    \n",
    "    try:\n",
    "        return genius.search_song(track,artist).lyrics\n",
    "    except:\n",
    "        print(track + ' by ' + artist + ' is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_songs(track_list,artist_list):\n",
    "    '''\n",
    "    function obtains lyrics and returns dataframe with columns for track, artist, lyrics\n",
    "    parameters:\n",
    "        track_list-->list of str \n",
    "        artist_list-->list of str\n",
    "    '''\n",
    "    lyrics_list = [get_lyrics(track_list[x],artist_list[x]) for x in range(len(track_list))] #get lyrics for each song\n",
    "    \n",
    "    return pd.DataFrame(data={'track':track_list,'artist':artist_list,'lyrics':lyrics_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(df,col,new_col):\n",
    "    '''\n",
    "    function returns dataframe with new column of cleaned text (song lyrics)\n",
    "    parameters:\n",
    "        df-->pandas dataframe\n",
    "        col-->column to clean (str)\n",
    "        new_col-->name of column with cleaned text (str)\n",
    "    '''\n",
    "    df[new_col] = df[col].str.lower() #make all text lowercase\n",
    "    df[new_col] = df[new_col].str.replace(r'\\n',' ') #replace '\\n' character with space\n",
    "    df[new_col] = df[new_col].str.replace(r'\\[[^\\[\\]]*]','') #remove brackets and inside text\n",
    "    df[new_col] = df[new_col].str.replace(r\"\\'\\w*\",'').str.replace(r'[^\\w\\d\\s]+','') #remove extra characters\n",
    "    df[new_col] = df[new_col].str.strip() #remove extra whitespace\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lyrics(df,col):\n",
    "    '''\n",
    "    function returns dataframe with column as list of words\n",
    "        tokenizes, removes stopwords from, and lemmatizes lyrics\n",
    "    parameters:\n",
    "        df-->pandas dataframe\n",
    "        col-->column to normalize\n",
    "    '''\n",
    "\n",
    "    df[col] = df[col].str.split() #tokenize lyrics\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df[col] = df[col].apply(lambda row: [w for w in row if w not in stop_words]) #remove stopwords\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def lemmatize_text(text):\n",
    "        '''\n",
    "        function returns lemmatized text\n",
    "        parameters:\n",
    "            text-->str\n",
    "        '''\n",
    "        return [lemmatizer.lemmatize(w) for w in text]\n",
    "    \n",
    "    df[col] = df[col].apply(lemmatize_text) #lemmatize words\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Songs to Analyze\n",
    "\n",
    "Read in the resulting dataframes from the spotify_analysis notebook, which were created as follows:\n",
    "\n",
    " - Started with the top five tracks for each of country, R&B/hip-hop, and rock/alternative as of the week of May 15, 2021, based on Billboard Top 100 charts (referred to as the \"seed tracks\")\n",
    " - Used Spotify's recommender algorithm to find the most similar songs to the seed tracks (returns a maximum of 100 songs per search)\n",
    " - Ranked the most similar songs by audio features using Euclidean distance\n",
    " - Fed the top ranking songs through Spotify's recommender algorithm until there were at least 1,000 songs per genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country\n",
    "df_cty = pd.read_csv('../Data/data/df_cty.csv')\n",
    "df_cty.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R&B/hip-hop\n",
    "df_rb = pd.read_csv('../Data/data/df_rb.csv')\n",
    "df_rb.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rock/alternative\n",
    "df_rock = pd.read_csv('../Data/data/df_rock.csv')\n",
    "df_rock.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Lyrics from Genius API\n",
    "\n",
    "Pull lyrics from the Genius API with the lyricsgenius wrapper and put into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Beer by HIXTAPE is not available\n",
      "Ballin' by Rvshvd is not available\n",
      "Gabrielle by Brett Eldredge is not available\n",
      "Forever Begins Tonight by The McClymonts is not available\n",
      "Tupelo Honey by JJ Grey & Mofro is not available\n",
      "#REDNEK by Gord Bamford is not available\n"
     ]
    }
   ],
   "source": [
    "#country\n",
    "df_cty_lyrics = get_df_songs(df_cty['track'],df_cty['artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bang Bang by Jessie J is not available\n",
      "Before He Cheats by Carrie Underwood is not available\n",
      "See What I've Become by Zack Hemsey is not available\n",
      "Stinger by RL Grime is not available\n",
      "Money On The Table by Belly is not available\n"
     ]
    }
   ],
   "source": [
    "#R&B/hip-hop\n",
    "df_rb_lyrics = get_df_songs(df_rb['track'],df_rb['artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greatest Hits Megamix by The Saturdays is not available\n",
      "Smells Blood by Kensuke Ushio is not available\n",
      "Ghost by Machine Girl is not available\n",
      "Unforgettable by French Montana is not available\n"
     ]
    }
   ],
   "source": [
    "#rock\n",
    "df_rock_lyrics = get_df_songs(df_rock['track'],df_rock['artist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Preprocess Lyrics\n",
    "\n",
    "Prepare lyrics for analysis by cleaning and normalizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows without lyrics\n",
    "df_cty_lyrics2 = df_cty_lyrics.dropna(subset=['lyrics']) #country\n",
    "df_rb_lyrics2 = df_rb_lyrics.dropna(subset=['lyrics']) #R&B/hip-hop\n",
    "df_rock_lyrics2 = df_rock_lyrics.dropna(subset=['lyrics']) #rock/alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean lyrics\n",
    "df_cty_cleaned = clean_lyrics(df_cty_lyrics2,'lyrics','words') #country\n",
    "df_rb_cleaned = clean_lyrics(df_rb_lyrics2,'lyrics','words') #R&B/hip-hop\n",
    "df_rock_cleaned = clean_lyrics(df_rock_lyrics2,'lyrics','words') #rock/alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize lyrics\n",
    "df_cty_norm = normalize_lyrics(df_cty_cleaned,'words') #country\n",
    "df_rb_norm = normalize_lyrics(df_rb_cleaned,'words') #R&B/hip-hop\n",
    "df_rock_norm = normalize_lyrics(df_rock_cleaned,'words') #rock/alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Dataframes to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country\n",
    "df_cty_norm.to_csv('../Data/df_cty_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R&B/hip-hop\n",
    "df_rb_norm.to_csv('../Data/df_rb_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rock/alternative\n",
    "df_rock_norm.to_csv('../Data/df_rock_lyrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
